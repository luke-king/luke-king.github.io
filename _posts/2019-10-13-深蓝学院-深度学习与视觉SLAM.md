---
layout: mypost
title: 深蓝学院--深度学习与视觉SLAM
categories: [线上直播与学术讨论]
---

# 深度学习与视觉SLAM

## 讲者介绍

杨楠，德国慕尼黑大学博士生，师从Daniel Cremers教授，并在其创立的Artisense担任高级计算机视觉研发工程师。主要研究方向为视觉SLAM及其与深度学习的融合。

## 背景介绍

![1](/posts/2019/10/13/1570964875090.png)

近几年，深度学习对于分类、检测、超分辨和光流等等领域都取得了很好的效果，甚至有些方法甚至可以称为“标杆”。

那么对于SLAM，深度学习如何与它进行结合呢？

![2](/posts/2019/10/13/1570964996954.png)

对于视觉SLAM来说，它可以简化为最大似然估计数学问题，通过图片像素的观测值去最大化真实空间中对应空间点的值的最大概率，得到一个好的模型参数。

![3](/posts/2019/10/13/1570965082491.png)

视觉SLAM可以分为两部分，前端（Front End）和后端（Back End）。在前端，做的第一个事情，是对数据进行选择，主要有key point selection和key frame selection；第二件要做的事就是数据的联系，特征之间的匹配和光流，直接法中的data association是被弱化的，因为它有比较理想的假设，但是现实中很多情况是复杂的，存在光照不均和噪点等情况；第三件事为pose和depth的估计，分为几何方法、直接法和基于优化的方法。

![4](/posts/2019/10/13/1570965734202.png)

对于后端，其实是一个非线性的最小二乘问题，解决的方法通常有高斯牛顿和LM算法等。

![5](/posts/2019/10/13/1570965905848.png)

目前视觉SLAM面临的问题和挑战。初始化、数据关联、缺乏语义信息以及如何设计出工程上能使用的deep learning系统都是还需要优化解决的问题。

## 视觉SLAM相关的深度学习

《Flow-net》是第一篇真正算得上解决optical flow的deep learning方法，下面简单介绍一下：

![6](/posts/2019/10/13/1570966242621.png)

loss function很简单，就是两帧图片对应光流点之间的像素差平方和再开根号，最后求和SUM。

![7](/posts/2019/10/13/1570966334285.png)

这是网络框架，主要是学习pixel和pixel之间的关系，这是简单的flow-net

![8](/posts/2019/10/13/1570966472524.png)

这是改进的更好的flow-net

![9](/posts/2019/10/13/1570966587956.png)

另一篇关于optical flow的deep learning方法是《PWC-Net》，左边的方法是用传统方法做optical flow，右边是PWC-net的方法做optical flow。

![10](/posts/2019/10/13/1570966636473.png)

还有一个跟SLAM相关的就是depth估计。对于depth estimation来说，《GC-Net》是个较好的方法。这是基于双目视觉的方法。这个方法用到了3D的convolution做基于双目的深度估计，目前用3D convolution做图像处理是一种在尝试的思路。

![11](/posts/2019/10/13/1570966768121.png)

双目视觉的关于depth estimation的深度学习方法 -- MonoDepth。MonoDepth的方法很多，讲者提供了这篇(《Unsupervised Monocular Depths Estimation with Left-Right Consistency》)经典的文章作为推荐。这篇文章是自监督的。

![12](/posts/2019/10/13/1570967287461.png)

这是这篇Mono-Depth实验的配图，最下面这一行是该方法的结果。

![13](/posts/2019/10/13/1570967420221.png)

sfm-Learner是能同时解决depth和pose的估计问题。但是他的depth效果稍微逊色于MonoDepth。



![14](/posts/2019/10/13/1572427308636.png)

他的难度在于optimization多了一个pose变量，增加了优化的难度，另一方面他毕竟是mono的，或多或少有scale方面的问题。

![15](/posts/2019/10/13/1570967537576.png)

这个方法是detection方面比较突出的工作了。

## 深度学习与视觉SLAM的结合

接下来讲一下讲者自己的关于深度学习和VSLAM结合的工作。

1、《Deep Virtual Stereo Odometry(DVSO)》(ECCV 2018)

对于大场景持续时间稍微长一点的SLAM任务，单目的效果还是不行，不能用，比如DSO

![16](/posts/2019/10/13/1572427728930.png)

虽然他最终的轨迹形状和ground truth差不多，但是会出现尺度的问题。有学者在前两年提出了一些端到端的深度学习方法解决SLAM的问题。

![17](/posts/2019/10/13/1572427849247.png)

不过这些方法都没有超越传统的方法。

![18](/posts/2019/10/13/1572427978735.png)

讲者在这样的背景下提出了mono-depth estimation和DSO相结合的方法，最终的结果是可以跟传统的stereo方法相同的效果。

![19](/posts/2019/10/13/1572428067937.png)

这是文章的loss function。

![20](/posts/2019/10/13/1572428130623.png)

作者在普通的net中增加了一个residual net。

![21](/posts/2019/10/13/1572428254932.png)

这是实验的量化结果。

![22](/posts/2019/10/13/1572428314892.png)

那么如何通过left和right的disparity map来做到用单目模拟出双目的系统。

![23](/posts/2019/10/13/1572432597758.png)

讲者给出了系统的做法，对于某个点来讲，用left disp来做初始化，想要用stereo photometric error来提高这个性能。将这个选到的点project到虚拟的image plane上，然后用right disp将虚拟的点back warping到原始的图中，得到了绿色和蓝色两个点。这样就模拟出了双目时的情况。

![24](/posts/2019/10/13/1572433047118.png)

这是实际的效果

![25](/posts/2019/10/13/1572433080406.png)

量化的结果。

2、CodeSLAM:《Learning a Compact, Optimisable Representation for Dense Visual SLAM》

![26](/posts/2019/10/13/1572433481829.png)

主要解决稠密点云重建，并且希望这个compact representation是可优化的。

![27](/posts/2019/10/13/1572433568352.png)

文章的network。

![28](/posts/2019/10/13/1572433781902.png)

CodeSLAM的sfm structure。

3、other works

![29](/posts/2019/10/13/1572433954415.png)



## 总结与展望

Deep Learning（DL）对于解决SLAM问题来说，目前为止还不能超过传统的SLAM系统。SLAM是一个集几何、优化于一身的较为复杂的系统。DL有自身的优势，它可以作为辅助性的方法去提高SLAM系统鲁棒性和准确性，这是一个比较好的一个思路。